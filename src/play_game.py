import torch
import numpy as np
import rlcard
from rlcard.utils import print_card

from src.config import AlphaHoldemConfig as cfg
from src.env.wrappers import AlphaHoldemWrapper
from src.model.resnet import AlphaHoldemResNet
import os

def format_cards(cards):
    """['SA', 'H10'] -> [â™ A, â™¥T] ë³€í™˜"""
    if not cards: return "[]"
    suits = {'S': 'â™ ', 'H': 'â™¥', 'D': 'â™¦', 'C': 'â™£'}
    ranks = {'T': '10', 'J': 'J', 'Q': 'Q', 'K': 'K', 'A': 'A'}
    formatted = []
    for card in cards:
        s, r = card[0], card[1]
        formatted.append(f"{suits.get(s, s)}{ranks.get(r, r)}")
    return str(formatted)

def get_human_action(legal_actions):
    """
    ì‚¬ìš©ìë¡œë¶€í„° í–‰ë™ì„ ì…ë ¥ë°›ëŠ” í•¨ìˆ˜
    [ìˆ˜ì •ë¨] RLCard í‘œì¤€ Action IDì— ë§ì¶° ë§¤í•‘ ìˆ˜ì •
    0: Fold
    1: Call/Check
    2: Raise Half
    3: Raise Pot
    4: All-in
    """
    action_map = {
        0: "Fold (í¬ê¸°)",
        1: "Call/Check (ë”°ë¼ê°€ê¸°)",
        2: "Raise (Half-Pot)",
        3: "Raise (Pot)",
        4: "All-in"
    }
    
    print("\n[Your Turn] ê°€ëŠ¥í•œ í–‰ë™:")
    valid_inputs = []
    
    # legal_actionsì— ìˆëŠ” í–‰ë™ë§Œ ë³´ì—¬ì¤Œ
    sorted_actions = sorted(legal_actions)
    for action_id in sorted_actions:
        action_name = action_map.get(action_id, f"Action {action_id}")
        print(f"  [{action_id}] {action_name}")
        valid_inputs.append(str(action_id))
        
    while True:
        user_input = input(">> í–‰ë™ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
        if user_input in valid_inputs:
            return int(user_input)
        print("âš ï¸ ê°€ëŠ¥í•œ í–‰ë™ ë²ˆí˜¸ë§Œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def run_game():
    print("\n" + "="*40)
    print(" ğŸƒ AlphaHoldem: Human vs AI Match ğŸƒ")
    print("="*40)

    # 1. í™˜ê²½ ë° AI ì„¤ì •
    raw_env = rlcard.make('no-limit-holdem', config={'seed': 42})
    env = AlphaHoldemWrapper(raw_env)
    
    # 2. ëª¨ë¸ ë¡œë“œ
    agent = AlphaHoldemResNet().to(cfg.DEVICE)
    model_path = os.path.join(cfg.CHECKPOINT_DIR, "alpha_holdem_siamese.pth")
    
    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return

    print(f"ğŸ¤– AI ëª¨ë¸ ë¡œë“œ ì¤‘... ({model_path})")
    try:
        agent.load_state_dict(torch.load(model_path, map_location=cfg.DEVICE))
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì—ëŸ¬: {e}")
        return

    agent.eval() 
    print("âœ… ì¤€ë¹„ ì™„ë£Œ! ê²Œì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n")

    while True:
        state, player_id = env.reset()
        done = False
        
        human_seat = np.random.choice([0, 1])
        ai_seat = 1 - human_seat
        
        print("-" * 40)
        print(f"ğŸ® New Game! (Human: Player {human_seat}, AI: Player {ai_seat})")
        
        while not done:
            current_player = player_id
            
            # --- [Human Turn] ---
            if current_player == human_seat:
                raw_state = env.env.get_state(player_id)
                # ë°ì´í„° êµ¬ì¡° í˜¸í™˜ì„± ì²˜ë¦¬
                info = raw_state['raw_obs'] if 'raw_obs' in raw_state else raw_state
                
                public_cards = info.get('public_cards', [])
                hand_cards = info.get('hand', [])
                pot = info.get('pot', 0)
                my_chips = info.get('my_chips', 0)
                all_chips = info.get('all_chips', [0, 0])
                opp_chips = all_chips[ai_seat]
                
                print(f"\n--- [My Turn] ---")
                print(f"ğŸ’° Pot: {pot} (Me: {my_chips} vs AI: {opp_chips})")
                print(f"ğŸƒ Board: {format_cards(public_cards)}")
                print(f"âœ‹ My Hand: {format_cards(hand_cards)}")
                
                if isinstance(raw_state['legal_actions'], dict):
                    legal_actions = list(raw_state['legal_actions'].keys())
                else:
                    legal_actions = raw_state['legal_actions']
                
                action = get_human_action(legal_actions)
                
            # --- [AI Turn] ---
            else:
                print(f"\nğŸ¤– AI Thinking...", end=" ")
                action, _ = agent.get_action(state, deterministic=True)
                
                # AI í–‰ë™ í•´ì„ (ìˆ˜ì •ë¨)
                action_names = ["Fold", "Call/Check", "Raise Half", "Raise Pot", "All-in"]
                action_str = action_names[action] if action < len(action_names) else str(action)
                print(f"-> AI chose: '{action_str}', '{action}'")

            # í™˜ê²½ ì§„í–‰
            state, player_id = env.step(action)
            if state is None:
                done = True

        # --- [ê²Œì„ ì¢…ë£Œ] ---
        payoffs = env.env.get_payoffs()
        human_reward = payoffs[human_seat]
        
        final_state_ai = env.env.get_state(ai_seat)
        final_state_human = env.env.get_state(human_seat)
        
        ai_info = final_state_ai.get('raw_obs', final_state_ai)
        human_info = final_state_human.get('raw_obs', final_state_human)
        
        print("\nğŸ Game Over")
        print(f"ğŸ¤– AI Hand: {format_cards(ai_info.get('hand', []))}")
        print(f"ğŸ§‘ My Hand: {format_cards(human_info.get('hand', []))}")
        print(f"ğŸƒ Board : {format_cards(ai_info.get('public_cards', []))}")
        
        if human_reward > 0:
            print(f"\nğŸ‰ You Win! (+{human_reward})")
        elif human_reward < 0:
            print(f"\nğŸ’€ You Lose... ({human_reward})")
        else:
            print(f"\nğŸ¤ Draw!")

        if input("\ní•œ íŒ ë” í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Enter: Yes / q: Quit): ").lower() == 'q':
            break

if __name__ == "__main__":
    run_game()